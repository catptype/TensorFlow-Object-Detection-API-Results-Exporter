{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Object Detection API Results Exporter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import library modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.dont_write_bytecode = True\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import shutil\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Object detection module\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as vis_utils\n",
    "from object_detection.builders import model_builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Avoid out of memory by setting GPU memory consumption growth\n",
    "gpu_list = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpu_list:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    \"model_path\": \"Model\",\n",
    "    \"extension\": ('.jpg', '.png'),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_selection(model_dir):\n",
    "    print(\"Scanning for models ... \", end=\"\")\n",
    "    legit_model_list = [model for model in os.listdir(model_dir)\n",
    "                        if os.path.exists(os.path.join(model_dir, model, 'pipeline.config')) and\n",
    "                        os.path.exists(os.path.join(model_dir, model, 'checkpoint', 'ckpt-0.index')) and\n",
    "                        os.path.exists(os.path.join(model_dir, model, 'label_map.pbtxt'))]\n",
    "    num_models = len(legit_model_list)\n",
    "    print(f\"Found {num_models}\")\n",
    "    \n",
    "    if len(legit_model_list) == 0:\n",
    "        return None\n",
    "    \n",
    "    if len(legit_model_list) == 1:\n",
    "        return legit_model_list[0]\n",
    "    \n",
    "    while True:\n",
    "        for idx, model in enumerate(legit_model_list):\n",
    "            print(f\"{idx}: {model}\")\n",
    "        try:\n",
    "            model_num = int(input(\"Select a model: \"))         \n",
    "            if 0 <= model_num < num_models:\n",
    "                return legit_model_list[model_num]\n",
    "            else:\n",
    "                print(\"Invalid input. Please try again.\")\n",
    "        except ValueError:\n",
    "            print(\"Invalid input. Please enter a valid number.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_xml_annotation(image_filename, objects):\n",
    "    root = ET.Element(\"annotation\")\n",
    "    \n",
    "    # Create basic image information\n",
    "    filename      = ET.SubElement(root, \"filename\")\n",
    "    filename.text = image_filename\n",
    "\n",
    "    # Object annotations\n",
    "    for obj in objects:\n",
    "\n",
    "        # Tree preparation\n",
    "        obj_elem  = ET.SubElement(root, \"object\")\n",
    "        classname   = ET.SubElement(obj_elem, \"classname\")\n",
    "        bndbox      = ET.SubElement(obj_elem, \"bndbox\")\n",
    "        xmin          = ET.SubElement(bndbox, \"xmin\")\n",
    "        ymin          = ET.SubElement(bndbox, \"ymin\")\n",
    "        xmax          = ET.SubElement(bndbox, \"xmax\")\n",
    "        ymax          = ET.SubElement(bndbox, \"ymax\")\n",
    "        score       = ET.SubElement(obj_elem, \"score\")\n",
    "        \n",
    "        # Data text\n",
    "        ## Class name\n",
    "        classname.text = obj[\"classname\"]\n",
    "\n",
    "        ## Bounding box coordinates\n",
    "        xmin.text = str(obj[\"xmin\"])\n",
    "        ymin.text = str(obj[\"ymin\"])\n",
    "        xmax.text = str(obj[\"xmax\"])\n",
    "        ymax.text = str(obj[\"ymax\"])\n",
    "\n",
    "        ## Detection score\n",
    "        score.text = str(obj[\"score\"])\n",
    "\n",
    "    # Create and return the ElementTree\n",
    "    tree = ET.ElementTree(root)\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(dir_processing, detection_model, category_index, threshold=0.5, export_roi=False, export_xml=False):\n",
    "    def prepare_path(path_str):\n",
    "        if not os.path.exists(path_str):\n",
    "            os.makedirs(path_str)\n",
    "\n",
    "    def detect_fn(model,tensor):\n",
    "        image, shapes = model.preprocess(tensor)\n",
    "        prediction_dict = model.predict(image, shapes)\n",
    "        detections = model.postprocess(prediction_dict, shapes)\n",
    "\n",
    "        # Post processing the detection results (Convert Tensor to Numpy)\n",
    "        num_detections = int(detections.pop('num_detections')) # Only num_detections has different shape\n",
    "        detections = {key: value[0, :num_detections].numpy() for key, value in detections.items()}\n",
    "        detections['num_detections'] = num_detections\n",
    "        detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "        return detections\n",
    "    \n",
    "    # Prepare result folders\n",
    "    export_path = os.path.join(dir_processing,'export_result')\n",
    "    complete_path = os.path.join(dir_processing,'complete')\n",
    "    prepare_path(export_path)\n",
    "    prepare_path(complete_path)\n",
    "\n",
    "    ## Load images\n",
    "    image_list = [os.path.join(dir_processing, file) for file in os.listdir(dir_processing) if os.path.isfile(os.path.join(dir_processing, file))]\n",
    "    image_list = [path for path in image_list if any(ext in path for ext in CFG[\"extension\"])]\n",
    "\n",
    "    for image_path in image_list:\n",
    "        # Set parameter\n",
    "        filename = os.path.basename(image_path)\n",
    "        _, ext = os.path.splitext(filename)\n",
    "\n",
    "        print(f'Running inference for {filename} ... ')\n",
    "\n",
    "        # Load an image and save into a numpy array\n",
    "        image_raw = Image.open(image_path)\n",
    "        image_np = np.array(image_raw.convert('RGB'))\n",
    "\n",
    "        # Convert the image to a tensor\n",
    "        image_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "                \n",
    "        # Run inference\n",
    "        detections = detect_fn(detection_model,image_tensor)\n",
    "\n",
    "        # Visualization of the results of a detection.\n",
    "        label_id_offset = 1\n",
    "        image_np_with_detections = image_np.copy()\n",
    "\n",
    "        # Get parameters\n",
    "        boxes = detections['detection_boxes']\n",
    "        max_boxes_to_draw = detections['num_detections']\n",
    "        scores = detections['detection_scores']\n",
    "\n",
    "        vis_utils.visualize_boxes_and_labels_on_image_array(\n",
    "                image_np_with_detections,\n",
    "                boxes,\n",
    "                detections['detection_classes']+label_id_offset,\n",
    "                scores,\n",
    "                category_index,\n",
    "                use_normalized_coordinates=True,\n",
    "                max_boxes_to_draw=max_boxes_to_draw,\n",
    "                min_score_thresh=threshold,\n",
    "                line_thickness=2,\n",
    "                agnostic_mode=False)\n",
    "\n",
    "        plt.figure(figsize=(8,8))\n",
    "        plt.imshow(image_np_with_detections)\n",
    "        plt.axis('off')\n",
    "        print('Done')\n",
    "        plt.show()\n",
    "    \n",
    "        ## Export image with ROI\n",
    "        if export_roi:\n",
    "            image_ROI    = Image.fromarray(image_np_with_detections) \n",
    "            filename_ROI = filename.replace(f\"{ext}\", f\"_ROI{ext}\")\n",
    "            destination = os.path.join(export_path,filename_ROI)\n",
    "\n",
    "            if ext == \".jpg\":\n",
    "                image_ROI.save(destination, \n",
    "                            format='JPEG', \n",
    "                            subsampling=0, \n",
    "                            quality=image_raw.info.get('quality', 95),\n",
    "                            optimize=True)\n",
    "            \n",
    "            elif ext == \".png\":\n",
    "                image_ROI.save(destination, \n",
    "                            format='png', \n",
    "                            subsampling=0, \n",
    "                            quality=image_raw.info.get('quality', 95),\n",
    "                            optimize=True)\n",
    "        \n",
    "        ## Export XML\n",
    "        if export_xml:\n",
    "            object_detection_results = []\n",
    "            # iterate over all objects found\n",
    "            for box, class_num, score in zip(boxes, detections['detection_classes'], scores):\n",
    "                if score < threshold:\n",
    "                    continue\n",
    "\n",
    "                class_name = category_index[class_num + 1]['name']\n",
    "                                \n",
    "                ymin = box[0] # left   or ymin\n",
    "                xmin = box[1] # right  or xmin\n",
    "                ymax = box[2] # top    or ymax\n",
    "                xmax = box[3] # bottom or xmax\n",
    "\n",
    "                object_detection_results.append({\n",
    "                    \"classname\": class_name,\n",
    "                    \"xmin\": xmin,\n",
    "                    \"ymin\": ymin,\n",
    "                    \"xmax\": xmax,\n",
    "                    \"ymax\": ymax,\n",
    "                    \"score\": score,\n",
    "                })\n",
    "\n",
    "            xml_tree = create_xml_annotation(filename, object_detection_results)\n",
    "            destination = os.path.join(export_path, filename.replace(ext, \".xml\"))\n",
    "            xml_tree.write(destination)\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        im_height = image_np_with_detections.shape[0]\n",
    "        im_width  = image_np_with_detections.shape[1]\n",
    "    \n",
    "        # iterate over all objects found\n",
    "        for i in range(min(max_boxes_to_draw, boxes.shape[0])):\n",
    "            if scores is None or scores[i] > threshold:\n",
    "\n",
    "                class_num  = detections['detection_classes'][i] # this will return class number start from 0\n",
    "                class_name = category_index[class_num + 1]['name']\n",
    "\n",
    "                # boxes[i] is the box which will be drawn\n",
    "                # boxes will return coordinates [ymin, xmin, ymax, xmax]\n",
    "                ymin = boxes[i][0] * im_height # left   or ymin\n",
    "                xmin = boxes[i][1] * im_width  # right  or xmin\n",
    "                ymax = boxes[i][2] * im_height # top    or ymax\n",
    "                xmax = boxes[i][3] * im_width  # bottom or xmax\n",
    "\n",
    "        \n",
    "\n",
    "                # Crop image\n",
    "                ymin = ymin.astype(int)\n",
    "                xmin = xmin.astype(int)\n",
    "                ymax = ymax.astype(int)\n",
    "                xmax = xmax.astype(int)\n",
    "\n",
    "                # Post processing if it is not square image\n",
    "                xmin, xmax, ymin, ymax = perfect_square(xmin, xmax, ymin, ymax, im_width, im_height)\n",
    "\n",
    "                # Crop image\n",
    "                image_crop = image_np[ymin:ymax, xmin:xmax] # output is array\n",
    "                image_crop = Image.fromarray(image_crop) # Convert array to image\n",
    "\n",
    "                # Save crop detected images\n",
    "                filename_temp = filename.replace(fileext, f'_object_{str(i)}_{class_name + fileext}')\n",
    "                filename_temp = os.path.join(dir_processing, class_name, filename_temp)\n",
    "                try:\n",
    "                    image_crop.save(filename_temp, \n",
    "                                format='JPEG', \n",
    "                                subsampling=0, \n",
    "                                quality=95, \n",
    "                                optimize=True)\n",
    "                except OSError:\n",
    "                    os.makedirs(os.path.join(dir_processing, class_name))\n",
    "                    image_crop.save(filename_temp, \n",
    "                                format='JPEG', \n",
    "                                subsampling=0, \n",
    "                                quality=95, \n",
    "                                optimize=True)        \n",
    "        \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializing():\n",
    "    ## Scan and look for models in Model folder\n",
    "    model = model_selection(CFG[\"model_path\"])\n",
    "\n",
    "    ## Parameter\n",
    "    PATH_TO_CFG      = os.path.join(CFG[\"model_path\"], model, 'pipeline.config')\n",
    "    PATH_TO_CKPT     = os.path.join(CFG[\"model_path\"], model, 'checkpoint', 'ckpt-0')\n",
    "    PATH_TO_LABELS   = os.path.join(CFG[\"model_path\"], model, 'label_map.pbtxt')\n",
    "\n",
    "    ## Load model\n",
    "    print('Loading model... ', end='')\n",
    "    start_time      = time.time()\n",
    "\n",
    "    ## Load pipeline config and build a detection model\n",
    "    configs         = config_util.get_configs_from_pipeline_file(PATH_TO_CFG)\n",
    "    model_config    = configs['model']\n",
    "    detection_model = model_builder.build(model_config=model_config, is_training=False)\n",
    "\n",
    "    ## Restore checkpoint\n",
    "    ckpt            = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "    ckpt.restore(PATH_TO_CKPT).expect_partial()\n",
    "\n",
    "    ## List of the strings that is used to add label for each box.\n",
    "    category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)\n",
    "\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print('Done! Took {} seconds'.format(elapsed_time))\n",
    "    return detection_model, category_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "detection_model, category_index = initializing()\n",
    "process(\"Images\", detection_model, category_index, threshold=0.8, export_roi=True, export_xml=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
